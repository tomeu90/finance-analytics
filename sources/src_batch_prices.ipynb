{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1fc7821-a1a8-4067-8e2f-c2946ba46e81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0083a6fa-0bb6-4556-86d1-25307e498785",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afe6cf2e-7d90-4063-94b8-6fcf7a61501d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import time\n",
    "from pyspark.sql.functions import regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3464d1a-1c09-474d-94b3-5999f33f0d61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TICKER_TABLE = \"finance_catalog.db_landing.src_raw_index_keys\"\n",
    "TABLE_NAME = \"finance_catalog.db_landing.src_raw_stock_prices\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b8d995c-596e-4eaa-aeba-49be7ce859eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tickers = (\n",
    "    spark\n",
    "        .table(TICKER_TABLE)\n",
    "        .select(regexp_replace(\"ticker\", \"\\\\.\", \"-\").alias(\"ticker\"))\n",
    "        .toPandas()[\"ticker\"]\n",
    "        .tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9001d9aa-5022-45fb-b558-fba82162062d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ticker_data = []\n",
    "batch_ini = 0\n",
    "batch_end = 0\n",
    "\n",
    "for ticker in tickers[batch_ini:batch_end]:\n",
    "\n",
    "    df = yf.download(ticker, period='1d', start=datetime(1900, 1, 1, 0, 0, 0), end=datetime.now(), auto_adjust=True)\n",
    "    df = df.reset_index()\n",
    "    df.columns = df.columns.droplevel(1)\n",
    "    df.columns = [re.sub(r\"\\W+\", \"_\", col).strip(\"_\").lower() for col in df.columns]\n",
    "    df['ticker'] = ticker\n",
    "    df['id'] = ticker + df['date'].dt.strftime('%Y%m%d')\n",
    "    df.set_index('id', inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    ticker_data.append(df)\n",
    "\n",
    "if ticker_data:\n",
    "    df = pd.concat(ticker_data, ignore_index=True)\n",
    "    df['volume'] = df['volume'].astype(float)\n",
    "\n",
    "(\n",
    "    spark\n",
    "        .createDataFrame(df)\n",
    "        .orderBy([\"ticker\", \"date\"], ascending=[True, False])\n",
    "        .write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"append\")\n",
    "        .saveAsTable(TABLE_NAME)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c89077b-95e1-45cd-bdb5-c67cae269cc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.table(TABLE_NAME).display()\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {TABLE_NAME}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "src_batch_prices",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
